{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRNN for Hindi Text Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMaiSdINPdTzmbbu3JpDqo2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarcasticvibes/CRNN-for-Hindi-Text-Recognition/blob/master/CRNN_for_Hindi_Text_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnqA0pYHuUpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "c38deae1-4d4c-448b-ce31-adbefcb155fe"
      },
      "source": [
        "! pip install albumentations --upgrade"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/40/a343ecacc7e22fe52ab9a16b84dc6165ba05ee17e3729adeb3e2ffa2b37b/albumentations-0.4.5.tar.gz (116kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.2)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.5-cp36-none-any.whl size=64378 sha256=753c659d833757a453fea3aa2931cbebc0dfab60725373f626d0060536aa4834\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/a0/61/e50f93165a5ec7e7f5d65064e513239505bc4c06d2289557d3\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=6d01fcbbe0e10a47bc3454df71663deffd8682556afa8f46427501e535cc04d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.5 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "albumentations",
                  "imgaug"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRmC7-7p6qRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import numpy as np\n",
        "\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDN2lqeUtGtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip captcha_dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdP1CESsHOg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BidirectionalLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, nIn, nHidden, nOut):\n",
        "        super(BidirectionalLSTM, self).__init__()\n",
        "\n",
        "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
        "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
        "\n",
        "    def forward(self, input):\n",
        "        recurrent, _ = self.rnn(input)\n",
        "        T, b, h = recurrent.size()\n",
        "        t_rec = recurrent.view(T * b, h)\n",
        "\n",
        "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
        "        output = output.view(T, b, -1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):\n",
        "        super(CRNN, self).__init__()\n",
        "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
        "\n",
        "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
        "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
        "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
        "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
        "\n",
        "        cnn = nn.Sequential()\n",
        "\n",
        "        def convRelu(i, batchNormalization=False):\n",
        "            nIn = nc if i == 0 else nm[i - 1]\n",
        "            nOut = nm[i]\n",
        "            cnn.add_module('conv{0}'.format(i),\n",
        "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
        "            if batchNormalization:\n",
        "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
        "            if leakyRelu:\n",
        "                cnn.add_module('relu{0}'.format(i),\n",
        "                               nn.LeakyReLU(0.2, inplace=True))\n",
        "            else:\n",
        "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
        "\n",
        "        convRelu(0)\n",
        "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
        "        convRelu(1)\n",
        "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
        "        convRelu(2, True)\n",
        "        convRelu(3)\n",
        "        cnn.add_module('pooling{0}'.format(2),\n",
        "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
        "        convRelu(4, True)\n",
        "        convRelu(5)\n",
        "        cnn.add_module('pooling{0}'.format(3),\n",
        "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
        "        convRelu(6, True)  # 512x1x16\n",
        "\n",
        "        self.cnn = cnn\n",
        "        self.rnn = nn.Sequential(\n",
        "            BidirectionalLSTM(512, nh, nh),\n",
        "            BidirectionalLSTM(nh, nh, nclass))\n",
        "        self.dropout  = nn.Dropout(p=.3)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        # conv features\n",
        "        conv = self.cnn(input)\n",
        "        b, c, h, w = conv.size()\n",
        "        assert h == 1, \"the height of conv must be 1\"\n",
        "        conv = conv.squeeze(2)\n",
        "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
        "        conv = self.dropout(conv)\n",
        "\n",
        "        # rnn features\n",
        "        output = self.rnn(conv)\n",
        "        output = self.dropout(output)\n",
        "        # add log_softmax to converge output\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def backward_hook(self, module, grad_input, grad_output):\n",
        "        for g in grad_input:\n",
        "            g[g != g] = 0   # replace all nan/inf in gradients to zero"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMMlT8QgJuWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CRNN(256, 3, 24, 256)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAcICAwMlUx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "650f59d2-dc40-4e29-9cc7-125995d7bf38"
      },
      "source": [
        "model"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRNN(\n",
              "  (cnn): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu3): ReLU(inplace=True)\n",
              "    (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
              "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu4): ReLU(inplace=True)\n",
              "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu5): ReLU(inplace=True)\n",
              "    (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
              "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu6): ReLU(inplace=True)\n",
              "  )\n",
              "  (rnn): Sequential(\n",
              "    (0): BidirectionalLSTM(\n",
              "      (rnn): LSTM(512, 256, bidirectional=True)\n",
              "      (embedding): Linear(in_features=512, out_features=256, bias=True)\n",
              "    )\n",
              "    (1): BidirectionalLSTM(\n",
              "      (rnn): LSTM(256, 256, bidirectional=True)\n",
              "      (embedding): Linear(in_features=512, out_features=24, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASSuNjUtds-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "a = os.listdir('/content/cropped_data/cropped_dir')[0]\n",
        "img = cv2.imread(f'/content/cropped_data/cropped_dir/{a}')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08cdGxTq_ka6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "66146efa-501a-4fb2-bbb1-4061a4e5abe4"
      },
      "source": [
        "a"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1010.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVFzLnuW_q-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FBpha4nwsBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "45b1c9c7-7850-4d15-f957-ac8c3cb4a4f1"
      },
      "source": [
        "cv2_imshow(img)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=79x72 at 0x7FB193E1F748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCROo480yBDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! tar -xvf cropped_data.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNewmv0N6ocY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "362b158a-39a9-44c2-a194-41362885708b"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "pad_char = '-PAD-'\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2VcB6XR7g_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gt_rep(word, letter2index, device = device_gpu):\n",
        "    gt_rep = torch.zeros([len(word), 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    #gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3ErQ61lCyLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to convert a batch of labels to coresponding represtentation that can be passed to the CRNN model\n",
        "def label_rep(labels, device = device_gpu, letter2index = hindi_alpha2index):\n",
        "  gt = []\n",
        "  len_ = torch.zeros(len(labels), dtype=torch.long).to(device)\n",
        "  for label in labels:\n",
        "    gt.append(gt_rep(ground_truth[label], letter2index, device))\n",
        "  rep = torch.zeros([len(labels),max(len(x) for x in gt) ], dtype=torch.long).to(device)\n",
        "  for index, label in enumerate(gt):\n",
        "    for i, char in enumerate(label):\n",
        "      rep[index][i] = char\n",
        "    len_[index] = len(label)\n",
        "  return len_, rep"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eqosabsIu2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to perform one training step given a batch of input images and their ground truths\n",
        "#We are using CTC loss function as our loss function\n",
        "def train_batch(net, opt, criterion, images, labels, device = device_gpu, batch_size = 10):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "\n",
        "    input = images\n",
        "    outputs = net(input)\n",
        "    input_lengths = torch.full(size=(batch_size,), fill_value = 31, dtype=torch.long)\n",
        "    target_lengths, target = label_rep(labels, device = device, letter2index = hindi_alpha2index)\n",
        "    loss = criterion(outputs, target, input_lengths, target_lengths)\n",
        "    opt.step()\n",
        "    return loss"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAWmmmbrCZnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training driver function which takes the hyper parameters and works accordingly\n",
        "def train_setup(net, lr = 0.01, n_epochs = 10, batch_size = 10, momentum = 0.9, display_freq=5, device = device_gpu):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.CTCLoss()\n",
        "    opt = optim.AdamW(net.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optim, mode='min', patience=5, factor=.3)\n",
        "    for e in range(n_epochs):\n",
        "      \n",
        "      trainloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
        "      n_batches = len(trainloader)-1\n",
        "      dataiter = iter(trainloader)\n",
        "      loss_arr = np.zeros(n_batches)\n",
        "\n",
        "\n",
        "      for i, data in tqdm_notebook(enumerate(trainloader), total = n_batches, unit = \"epoch\"):\n",
        "          images, labels = data['image'], data['label']\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          loss_arr[i] = train_batch(net, opt, criterion, images, labels, device = device, batch_size = batch_size)\n",
        "          \n",
        "          if e%display_freq == display_freq-1:\n",
        "              clear_output(wait=True)\n",
        "              \n",
        "              print('Epoch',e,'Iteration', i, 'Loss', loss_arr[:i+1].mean())\n",
        "              print('\\n\\n')\n",
        "      scheduler.step()  \n",
        "    torch.save(net.state_dict(), 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ZaJM199e91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_transforms():\n",
        "    return A.Compose(\n",
        "        [\n",
        "            A.OneOf([\n",
        "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
        "                                     val_shift_limit=0.2, p=0.9),\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, \n",
        "                                           contrast_limit=0.2, p=0.9),\n",
        "            ],p=0.9),\n",
        "            A.ToGray(p=0.01),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.Resize(height=32, width=64, p=1),\n",
        "            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, p=0.5),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], \n",
        "        p=1.0, \n",
        "    )\n",
        "\n",
        "def get_valid_transforms():\n",
        "    return A.Compose(\n",
        "        [\n",
        "            A.Resize(height=32, width=64, p=1.0),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], \n",
        "        p=1.0\n",
        "    )"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8lq0eFT_Mds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader:\n",
        "  def __init__(self, test=False):\n",
        "    if test:\n",
        "      self.aug = get_valid_transforms()\n",
        "    else:\n",
        "      self.aug = get_train_transforms()\n",
        "    \n",
        "    self.image_ids = enumerate(os.listdir('/content/cropped_data/cropped_dir'))\n",
        "    with open('/content/cropped_data/annotations.txt') as f:\n",
        "      gt = f.read()\n",
        "      gt = list(gt.split('\\n'))\n",
        "      gt = list(map(str.split, gt))\n",
        "      label = []\n",
        "      for i, anno in enumerate(gt):\n",
        "        gts = [a for a in anno]\n",
        "        if(len(gts)<2):\n",
        "          continue\n",
        "        label.append(gts[1])\n",
        "    self.labels = label\n",
        "  def __len__(self):\n",
        "    return len(self.image_ids)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    image = cv2.imread(f'/content/cropped_data/cropped_dir/{item}.jpg')\n",
        "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = self.aug(image = np.array(image))['image']\n",
        "    #image = np.transpose(image, (2, 0, 1))\n",
        "    return {\n",
        "        'image':image,\n",
        "        'label':self.labels[item]\n",
        "    }"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWM8T5yzRyv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = DataLoader()"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLLh49ilShwX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5d816f48-e0db-475f-b25b-9743f216a353"
      },
      "source": [
        "dataset[5]['image'].shape"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70CUX40EStg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}